---
title: "ITEC 621 - Homework 1"
author: "Johnson ODEJIDE"
date: "February 05, 2023"
output:
  word_document:
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
subtitle: R, Stats and Regression Refresher
---

## Overview -- Read this carefully

The goal of this homework is to practice with R, R Studio, R Markdown and with simple statistical analysis. Parts of This homework are somewhat similar to HW0 in the KSB-999 R Overview for Business Analytics (Canvas), which you were required to complete on your own. The rest of the homework is about the stats and regression refresher.

** The following applies to all homework assignments in this class, so please read carefully. **

It is not a bad idea to complete this homework (and all homework) in a plain R script first. Once you are satisfied that all your R scripts work properly, you can then open the R Markdown template file **HW1_YourLastName.Rmd**, re-name it using **your actual last name** and copy over your work to the corresponding code chunk sections in the R Markdown template. If you are comfortable working in R Markdown, you can work directly in the HW template.

## Knitting (up to 10 pts.)

You are required to **knit ALL** your homework R Markdown files into a **Word** (preferred), PDF or HTML file. Learning how to prepare analytic reports using the `{knitr}` package (which is what R Markdown uses) is an important learning objective of this course. You are expected to submit your homework in a properly knitted with **business-like** formatting and appearance. **No knitting, inadequate knitting and/or improper formatting of the document will carry point deductions up to 10 points.**

**Important Notes about Knitting and Formatting:** 

- Your R code must be visible in your knitted document. This means that your R Markdown file **MUST** have the attribute `echo = T` in the **{r global_options}** setting below. We need to be able to see your R code to grade your homework. The template provided for the homework usually has the `echo = T` setting, but it is your responsibility to ensure that it is set correctly.

- The knitted file must have a table of contents that include all `Heading 1 (#)` and `Heading 2 (##)` entries. Please review your R Markdown file to ensure that these headings are the only text with `#` or `##` tags. Otherwise, your narrative text will be improperly formatted (with large blue font) and the text will also appear in the table of contents, which is not appropriate for a business document.

- Enter your narrative answers to interpretation questions in the text areas (without `#` tags), not in the R code chunk. It is OK to enter text in the R code chunks with a `#` tag, but these should be used to make comments and annotations about your script, not for interpretations. Related to this, please note that comments in R code chunks with the `#` tag sometimes don't knit well and the text doesn't wrap at the end of the line, preventing me from being able to read all your comments. This happens frequently when knitting to PDF files, but I have seen this problem with Word too. Please be aware that **I cannot give you credit for what I cannot read !!**. It is your responsibility to ensure that I can read all your text. If a line is not wrapping correctly, you can always break it. 

- Overall, anything that would not be acceptable to a management or client audience is not acceptable in knitted documents. 

## Interpretations: 

The goal in this course is NOT to make you proficient in R, although you will get a lot of R practice in this class. One important goal is to be able to extract meaningful business insights from your analysis. As such, all **interpretation questions** will be graded rigorously in every homework. Please think through every interpretation question and respond concisely, but accurately. Your analysis must demonstrate that you understand how to interpret the output of your models. 

## Submission: 

I will always display the solution output in the homework instructions, so that you can compare your results against the solution. In questions involving random sampling, your outputs may differ slightly from the solution. This is OK, but if in doubt, please ask a TA or me. Once done, submit your knitted document in Canvas.

## Global Options

R Markdown allows you to set global options that affect the entire knitted document. But you can change these options in specific R code chunks. Specific option settings override the global settings. For example, to show all your code, set the attribute `echo = T` in the **global_options** (the `warning = F` and `message = F` attributes suppress warnings and messages in your knitted file.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```

## Q1. Functions (10 pts.)

Let's refresh some concepts from HW0. Write a function to compute and `return()` the hypotenuse of a squared triangle of sides a and b. The hypotenuse is equal to the square root of the sum of the squares of the two sides (i.e., `round(sqrt(a^2 + b^2), digits = 2`). Call this function **hyp** and pass arguments a and b (i.e., `function(a, b)`). Notice that the `sqrt()` function is embedded inside the `round()` function to limit the number of decimal points displayed.

In the next line after the function definition, store a value of **7** in a variable named **a** and **10** in **b**. Then, use the function `paste()` to output this result: `"The hypotenuse of a triangle with sides", a, "and", b, "is", hyp(a, b)`. **Technical note:** in some R routines (such as in functions), `paste()` will compute a value, but will not display a result (and sometimes it will). To display your results, enclose everything in the `paste()` function within the `print()` function.

**A technical tip:** A common mistake is to have an incorrect number of closing parentheses in a formula with functions. In the example above you have 3 opening parentheses, one for `print(` one for `paste(` and one for `hyp(`. This means that you need to have 3 closing parentheses somewhere to close each of the 3 functions.

```{r hypotenuse}
hyp <- function(a, b){
  return(round(sqrt(a^2 + b^2), digits = 2))
}

a <- 7
b <- 10

print(paste("The hypotenuse of a triangle with sides", a, "and", b, "is", hyp(a, b)))
```

## Q2. Data Work (10 pts.)

Note: The **PizzaCal** data set contains the grams of moisture, protein, etc. per slice of pizza. The pizzas are categorized by brand and whether the brand is imported (1) or domestic (0).

2.1 Read the **PizzaCal.csv** data table into a data frame named **Pizza** (tip: use the `read.table()` function with `header = T`, `row.names = 1` and `sep = ","`. Display the **first 6 rows** (use the `head()` function) of this data set. 

```{r ReadCSV}
Pizza <- read.table("../../../Dataset/PizzaCal.csv", header = T, row.names = 1, sep = ",")
head(Pizza)
```

2.2 Then, display the object class for the **Pizza** data frame and for the vectors **cal** (i.e., `Pizza$cal`), **fat** and **brand**.

```{r Class}
class(Pizza)

class(Pizza$cal)

class(Pizza$fat)

class(Pizza$brand)
```

2.3 Then create a matrix called **Pizza.mat** that contains only the quantitative variables in the data set (i.e., mois through cal - tip: the index `[, 3:9]` will select all rows and columns 3 to 9 in the matrix). Display the class of the **Pizza.mat** object and then list the first 6 rows of this matrix, just to ensure you did the right thing.

```{r matrix}

Pizza.mat <- as.matrix(Pizza[, 3:9]) 

class(Pizza.mat)

head(Pizza.mat)
```

## Q3. Descriptive Statistics (10 pts.)

Let's analyze the data quantitatively. First get a`summary()` of the **Pizza** data frame and inspect the frequencies. Then load the **{psych}** library and display the descriptive statistics for the data set using the `describe()` function, but only for the quantitative variables in columns 3 to 9. Since this function provides many descriptive stats, let's limit the display to a few important statistics in columns 1 to 9. To do this, add the index `[3:9, 1:9]` after the `describe()` function. 

```{r Descriptives}
summary(Pizza)

library(psych)
describe(Pizza)[3:9, 1:9]
```

## Q4. Correlation Analysis (10 pts.)

4.1 Then create a correlation object named **Pizza.cor** using the `cor()` function. Then load the **{corrplot}** library and feed this **Pizza.cor** object into the `corrplot()` function. Add the parameter `"order = hclust"` to group the cluster the variables by correlation strength, and the parameters `method = number` to display correlation values. Then run the same `corrplot()` function, but this time use `method = ellipse` to get a graphical display.

```{r Correlation}
Pizza.cor <- cor(Pizza.mat)

library(corrplot)
corrplot(Pizza.cor, method = "number", order = "hclust")
corrplot(Pizza.cor, method = "ellipse", order = "hclust")
```

4.2 Based on the correlation results above, suggest two desirable predictors to include in a regression model with **cal** as the outcome variable. Provide a brief rationale for your selection.

**Answer:**
Two desirable predictors for **cal** would be ***mois*** and ***fat***.
As observed from the correlation plot, `mois` has a correlation of ***-0.76*** indicating a moderately strong _negative relationship_ with `cal` while `fat` has a correlation of ***0.76*** also, indicating a _positive relationship_ with `cal`. From the ellipse correlation plot, the darker the blue or red, the more correlated it is. The red indicates a negative correlation while the blue indicates a positive correlation. From the plot, it was observed that the darkest blue is `fat` while the darkest red is `mois`.

## Q5. Descriptive Analytics: Normality (10 pts.)

5.1 Divide the graph output to 1 row and 2 columns (`par(mfrow = c(1, 2))`). Then draw a histogram for the **cal** variable. Title your diagram **"Calories Histogram"** and label the x axis **"Calories"**. 

Then draw a **QQ Plot** to inspect the normality of this variable (tip: this is a 2 step process; first draw the QQ Plot with the `qqnorm()` function and give it a main title of `"Calories QQ Plot"`), then draw the QQ Plot line with the function `qqline()`.

Also, draw a histogram and a QQ Plot for the **fat** variable. Title the histogram **Fat Histogram"** and label the x axis **Fat**. Title the QQ Plot **Fat QQ Plot"**. Then reset the graph output to 1 row and 1 column.

```{r Normality}
par(mfrow = c(1, 2))

hist(Pizza$cal, main = "Calories Histogram", xlab = "Calories")

qqnorm(Pizza$cal, main = "Calories QQ Plot")
qqline(Pizza$cal)

hist(Pizza$fat, main = "Fat Histogram", xlab = "Fat")

qqnorm(Pizza$fat, main = "Fat QQ Plot")
qqline(Pizza$fat)

par(mfrow = c(1, 1))
```

5.2 Briefly answer: Do calories and fat appear to be normally distributed? Why or why not.

**Answer:**

Calories appears to be normally distributed. There is a noticeable trace of bell shape on the histogram and the qq plot also justifies this. Most of the data are on the line of the qqplot with only a few number of deviation.

Fat does not appear to be normally distributed. The histogram does not reveal a bell shape. Furthermore, the qqplot shows that just a few observations are on the line while most of the observations are off the line.


## Q6. Descriptive Analytics: Boxplots and ANOV (10 pts.)

6.1 Divide the graph output to 1 row and 2 columns. Then draw 2 boxplots one for **fat** by **brand** and another for **cal** by **brand**. Then reset the graph output back to 1 row and 1 column.

```{r boxplots}
par(mfrow = c(1, 2))

boxplot(fat~brand, data = Pizza)

boxplot(cal~brand, data = Pizza)

par(mfrow = c(1, 1))
```

6.2 Then conduct two **ANOVA** tests using the `aov()` function, one to evaluate if **fat** varies **by brand** and another to evaluate if **calories** vary **by brand**. Store the results of the first **ANOVA** test in an object named **aov.fat** [not aov.brand] and the second one named **aov.cal**. Then display the summary of each of these objects, but write the function `cat("\n")` in between the two summaries to separate the displays with a blank line. **Technical note:** the `cat()` function concatenates and prints strings and `"\n"` is the code for a new line.

```{r anova}
aov.fat <- aov(fat ~ brand, data = Pizza) # ANOVA - fat by brand
aov.cal <- aov(cal ~ brand, data = Pizza) # ANOVA - cal by brand

# Get the summaries of the ANOVA table
summary(aov.fat)
cat("\n") # The function cat concatenates and prints strings and "\n" is the code for a new line.
summary(aov.cal)
```

6.3 Briefly answer: Does fat vary by brand? And, do calories vary by brand? Briefly explain why or why not. Please refer to **both**, the visual boxplot and the quantitative ANOVA output.

**Answer:**

The boxplot for fat by brand tends to overlap in most cases, however, since this overlap is not noticeable in all cases, we can say that fat varies by brand and this is justified by the output of the anova `aov` function with a p-value < 0.0001 indicating a strong evidence that the means between the groups vary.
Similarly, the variation in calories is more obvious as the plots show a very minute overlap and in most cases they do not overlap. This is also observed in the anova table for cal by brand that there is a strong evidence that calories vary by brand (p-value < 0.0001).


## Q7. Simple Linear Regression Model (10 pts.)

7.1 Fit a **simple** linear regression model object with the `lm()` function to predict **calories** using **fat** as the only predictor. Store your linear model results in an object named **fit.simple**. Then display the `summary()` results. 

```{r fit.simple}

fit.simple <- lm(cal ~ fat, data = Pizza)
summary(fit.simple)
```

7.2 If **fat** is in grams per slice and **cal** is in calories per slice, provide a brief **interpretation** of both, the **significance** and **effect** of fat on cal. 
**Answer:**

The effect of fat is significant (p-value < 0.0001), providing a _strong evidence_ that `fat` has an effect on `calories` and this effect is positive - indicating that on average, an additional 1 gram per slice of fat is estimated to ***increase*** the calories by 5.28 calories per slice.



## Q8. Linear Regression Model with a Binary Predictor (10 pts.)

8.1 Now fit a larger linear regression model, same as above, but add **import** as a predictor. Name the resulting linear model **fit.dummy**. Then display the `summary()` results. 

```{r fit.dummy}
fit.dummy <- lm(cal ~ import + fat, data = Pizza)
summary(fit.dummy)
```

8.2 Provide a brief **interpretation** of both, the **significance** and **effect** of **import** on **cal**.

**Answer:**

The effect of **import** on the model is both significant (p-value < 0.0001), providing a strong evidence that `import` has an effect on the model.  This effect is also positive such that on average, holding everything else constant, calories is estimated to be 73.6 calories per slice more for every import.



## Q9. Multivariate Linear Model (10 pts.)

9.1 Now fit a larger linear regression model to predict calories, using import, fat, carb and mois as predictors. Name the resulting linear model **fit.full**. Then display the `summary()` results. 

```{r fit.full}
fit.full <- lm(cal ~ import + fat + carb + mois, data = Pizza)
summary(fit.full)
```

9.2 Then provide a brief **interpretation** of both, the **significance** and **effect** of both, **import** and **fat** on **cal**.

**Answer:**

In the full model, although **import** has a positive effect on **cal**, this effect is not significant (p-value = 0.897). However, **fat** has a significantly positive effect on **cal** (p-value < 0.0001) indicating that holding everything else constant, on average, an increase in fat by 1 grams per slice is estimated to increase the calories by 5.03 calories per slice.


9.3 Briefly answer: The **import** predictor was significant in the model in 8.1 above, but it is no longer significant in this multivariate model. Which result do you believe more, the one in 8.1 or this one? Briefly explain why.

**Answer:**

In the `"dummy"` model (8.1), it matters to the model that there is an import or not and this is a somewhat biased model as it doesn't consider other variables. However, on the full model, it shows that fitting the model with additional (significant) predictors makes **import** insignificant. In other words, holding everything else constant, it doesn't matter if the brand was imported or not, it doesn't have an effect on the calories of the Pizza.


## Q10. Residual Plots and Model Evaluation (10 pts.)

10.1 Let's inspect the results and provide some final storytelling. First, `plot()` the **fit.full** object. This function yields 4 residual plots, but for now, we are only interested in the second residual plot, so add the attribute `which = 2`, which renders the QQ Plot of the residuals. 

```{r residualplot}
plot(fit.full, which = 2)
```

10.2 Then conduct an **ANOVA** test to compare all 3 models together, **fit.simple, fit.dummy and fit.full.

```{r residuals}
anova(fit.simple, fit.dummy, fit.full)
```

10.3 Which of the three models is preferred? Briefly explain why. 

**Answer:**

The full model is preferred. From the ANOVA test, it was observed that there is a significant difference between the full model and the dummy model. Further more, the residual sum of squared of the dummy model is very high (181469 on 297 degrees of freedom) compared to the full model where it is much more reduced (1406 on 295 degrees of freedom) indicating a lesser variation in the latter. This is so because looking at the full model, approximately 100% of the variability of the response variable _cal_ is explained by the model while in the dummy model, about 84.2% of the variability can be explained by the model.